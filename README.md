# ğŸš¦ Automated Annual Air Quality Monitoring for Bandung

## ğŸ“„ Overview

Proyek ini mengimplementasikan pipeline data end-to-end untuk memonitor kualitas udara tahunan (PM2.5) di Bandung. Dimulai dengan data historis dari laporan publik sebagai fondasi, arsitektur ini dirancang untuk dapat diperluas dengan sumber data dinamis seperti API di masa depan. Tujuan utamanya adalah mengotomatisasi analisis tren jangka panjang untuk mendukung kebijakan lingkungan dan memberdayakan masyarakat dengan data yang mudah diakses.

Pipeline ini diorkestrasi oleh Apache Airflow, menggunakan Python untuk ekstraksi data ke Neon DB (PostgreSQL) yang berfungsi sebagai staging area dan data warehouse. Transformasi dan agregasi data dijalankan oleh Apache Spark, dengan hasil akhir yang divisualisasikan pada dashboard Streamlit interaktif. Platform ini juga dirancang untuk dapat mengirimkan notifikasi otomatis melalui Email atau Telegram jika terdeteksi tingkat polusi yang melebihi ambang batas.

## ğŸ¯ Objectives

- Mengkonsolidasikan data kualitas udara tahunan (PM2.5) dari file Excel yang disediakan
- Menghitung rata-rata tahunan, nilai maksimum, dan mendeteksi outlier untuk metrik polusi
- Menandai tahun-tahun dengan lonjakan polusi yang tidak biasa berdasarkan logika ambang batas
- Memvisualisasikan tren jangka panjang via dashboard interaktif
- Memberi tahu pemangku kepentingan secara otomatis melalui email atau Telegram

## ğŸ“ Project Structure

```
bandung_airbatch/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ Kesehatan_Udara_Bandung_2022.xlsx
â”‚   â”œâ”€â”€ Kesehatan_Udara_Bandung_2023.xlsx
â”‚   â”œâ”€â”€ Kesehatan_Udara_Bandung_2024.xlsx
â”‚   â””â”€â”€ Kesehatan_Udara_Bandung_2025.xlsx
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ Dag_Bandung_yearly_air_quality_pipeline.py
â”‚   â”œâ”€â”€ Python Script_extract_local_csv.py
â”‚   â””â”€â”€ create_table_staging_raw_air_quality.sql
â”œâ”€â”€ spark_jobs/
â”œâ”€â”€ streamlit_app/
â”‚   â”œâ”€â”€ Streamlit requirements.txt
â”‚   â””â”€â”€ Streamlit.py
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ PySpark Job_Bandung_yearly_air_quality.py
â””â”€â”€ requirements.txt
```

## ğŸ“š Data Sources

Saat ini menggunakan dataset dari Nafas Indonesia dalam format Excel. Untuk pengembangan masa depan, akan diintegrasikan dengan:

- [Databoks](https://databoks.katadata.co.id/layanan-konsumen-kesehatan/statistik/3b72788adeb2920/kualitas-udara-di-kota-besar-indonesia-buruk-jauh-dari-standar-who)
- BMKG API â€“ archived daily JSON data
- data.go.id â€“ downloadable CSV/JSON datasets
- Nafas Indonesia â€“ sensor reports in PDF/Excel format
- IQAir Bandung â€“ scraped AQI and pollutant archive

## âœ¨ Features

- ğŸŒ **Ekstraksi Data Otomatis**: Membaca file Excel secara otomatis dengan potensi ekspansi ke API dan web scraping
- ğŸ—„ï¸ **Data Storage**: Staging PostgreSQL dan warehouse terpartisi untuk kueri cepat
- âš¡ **Batch Processing**: Spark jobs untuk menghitung statistik tahunan
- ğŸ“Š **Interactive Dashboard**: Dashboard Streamlit dengan filter dan visualisasi
- ğŸ”” **Alert System**: Notifikasi otomatis via Telegram/email ketika polusi melebihi ambang batas
- ğŸ” **Orchestration**: Penjadwalan otomatis dengan Apache Airflow
- ğŸ³ **Containerization**: Docker Compose untuk deployment yang mudah

## ğŸ› ï¸ Tech Stack

| Component | Tool |
|-----------|------|
| **Orchestration** | Apache Airflow |
| **Extraction & ETL** | Python (requests, pandas, tabula-py) |
| **Batch Processing** | Apache Spark |
| **Data Storage** | PostgreSQL (Neon DB) |
| **Visualization** | Streamlit |
| **Alerting** | SMTP, Telegram Bot |
| **Containerization** | Docker, Docker Compose |

## ğŸ”„ Pipeline Overview

```
[1. Data Source]
    (Excel Files)
         â†“
[2. Data Extraction] â€”â€”â€” (Orchestrated by Apache Airflow)
    (Python Script)
         â†“
[3. Staging Area]
    (Neon DB PostgreSQL)
         â†“
[4. Data Transformation] â€”â€”â€” (Orchestrated by Apache Airflow)
    (Apache Spark)
         â†“
[5. Data Warehouse]
    (Neon DB PostgreSQL)
         â†“
[6. Visualization & Actions]
    (Streamlit Dashboard)
```

### Workflow Detail

#### 1. ETL (Airflow DAG yearly_air_quality_pipeline)
- **Extract**: Membaca data dari file Excel tahunan yang disediakan
- **Load (Staging)**: Menyimpan data mentah ke tabel `staging.raw_air_quality` di PostgreSQL

#### 2. Analytics Generation (Spark Job)
- **Transform**: Membaca data dari staging, memvalidasi skema, dan melakukan transformasi dasar
- **Load (Warehouse)**: Menyimpan data matang yang sudah diolah ke tabel `warehouse.fact_yearly_air_quality`

#### 3. Visualization (Streamlit)
- **Query**: Aplikasi Streamlit melakukan kueri langsung ke tabel warehouse di PostgreSQL
- **Display**: Menampilkan tren kualitas udara tahunan dalam bentuk grafik batang dan tabel interaktif

## ğŸš€ Quick Start

### Prerequisites
- Docker & Docker Compose
- Git

### Setup

1. **Clone repository**
```bash
git clone <repository-url>
cd bandung_airbatch
```

2. **Setup environment**
```bash
docker-compose up -d
```

3. **Access services**
   - **Airflow**: http://localhost:8080
   - **Streamlit**: http://localhost:8501

### Database Connection
```bash
psql 'postgresql://neondb_owner:npg_odbj5JHY0pwO@ep-cold-grass-a18xlnz0-pooler.ap-southeast-1.aws.neon.tech/neondb?sslmode=require&channel_binding=require'
```

## âš ï¸ Current Limitations

- Dataset bersifat statis, belum mendukung incremental load atau streaming
- Tidak semua field (seperti tanggal transaksi) diproses secara time-series (fokus saat ini pada agregasi tahunan)
- Belum terhubung ke BI tools lain seperti Looker/Power BI
- Proses ekstraksi data masih bergantung pada file Excel yang disiapkan secara semi-manual
- Platform hanya berjalan dalam mode batch (tahunan), cocok untuk analisis historis tetapi tidak untuk pemantauan real-time

## ğŸ”® Future Development Plans

- **Time Dimension Enhancement**: Menambah analitik per bulan atau per hari untuk analisis tren yang lebih granular
- **Automated Reporting**: Scheduler untuk export PNG otomatis dari dashboard
- **API Integration**: Sinkronisasi data dari API eksternal (BMKG, OpenAQ) untuk otomatisasi penuh
- **Real-time Processing**: Implementasi streaming menggunakan Apache Kafka dan Spark Streaming
- **Advanced Analytics**: Analisis prediktif (forecasting) dan korelasi dengan data cuaca atau lalu lintas
- **BI Tools Integration**: Koneksi ke Looker, Power BI, atau tools visualisasi enterprise lainnya

## ğŸ‘¤ Author

**Rafli Firmansyah**  
Project ini dibangun untuk tujuan edukasi dan pengembangan portofolio di bidang data engineering.

## ğŸ“ License

Proyek ini ditujukan untuk penggunaan edukasi dan portofolio.

## ğŸ“ Support

Jika ada pertanyaan atau saran pengembangan, silakan buat issue atau hubungi penulis.

---

> **Note**: Project ini masih dalam tahap pengembangan dan akan terus disempurnakan dengan fitur-fitur tambahan.
